# Qasper Dataset Metadata
# This file is committed to git to provide dataset context to AI
# Actual PDF files are NOT committed (cached locally)

name: Qasper
version: "1.0"
type: qasper
source_url: https://huggingface.co/datasets/allenai/qasper
reference_url: https://arxiv.org/abs/2105.03011

description: >
  QASPER (Question Answering on Scholarly Publications Enhanced by Retrieval).
  1,585 NLP research documents with 5,049 information-seeking questions.
  Questions asked by regular readers, answered by NLP practitioners.
  Tests RAG systems on long-form scientific documents.

splits:
  train:
    documents: 888
    questions: ~2850
    source: HuggingFace datasets

  validation:
    documents: 281
    questions: ~900
    source: HuggingFace datasets

  test:
    documents: 416
    questions: ~1300
    source: HuggingFace datasets

structure:
  format: PDF (downloaded from arxiv) + HuggingFace metadata
  document_source: arxiv.org (PDFs)
  questions_source: HuggingFace datasets library
  schema:
    doc_id: string (arxiv ID, e.g., "1909.00694")
    title: string (document title)
    pdf_text: string (raw extracted text - no preprocessing)
    qas:
      - question: string
        question_id: string (unique hash)
        answers: list (multiple annotators, multiple answer types)

answer_types:
  - extractive: Spans from document text
  - abstractive: Free-form text answers
  - boolean: Yes/No answers
  - unanswerable: Questions with no answer in document

features:
  - Full-text research documents (long context, 10k+ tokens)
  - Expert annotations (both Q and A)
  - Multiple answer types
  - Evidence grounding
  - Domain-specific (NLP documents)
  - Realistic information-seeking questions

sample_documents:
  - id: "1909.00694"
    title: "Minimally Supervised Learning of Affective Events Using Discourse Relations"
  - id: "1909.01380"
    title: "Clinical Concept Extraction with Contextual Word Embedding"
  - id: "1909.01642"
    title: "Incorporating Priors with Feature Attribution on Text Classification"

usage:
  loader: DatasetLoader.load_qasper(split='train')
  preprocessor: QasperPreprocessor
  options:
    - split: 'train' | 'validation' | 'test'
    - max_docs: int (default None = all documents, set limit for testing)
    - filter_unanswerable: bool (default True)
  examples:
    - Load all documents: DatasetLoader.load_qasper(split='train')
    - Load 10 documents: DatasetLoader.load_qasper(split='train', max_docs=10)

data_storage:
  pdfs: data/datasets/Qasper/pdfs/*.pdf (NOT committed, cached locally)
  parquet: data/datasets/Qasper/cache/*.parquet (NOT committed, cached locally)
  metadata: Loaded from HuggingFace parquet files
  cache_policy: Parquet and PDFs cached after first download

notes:
  - PDFs downloaded on first load (cached for reuse)
  - Rate limiting: 3s between downloads (respect arxiv)
  - Raw PDF text used (no preprocessing - realistic RAG eval)
  - Documents that fail to download are skipped
  - Requires: arxiv>=2.0.0, pypdf>=3.0.0, datasets>=4.0.0
  - License: CC-BY-4.0

evaluation_metrics:
  - Exact Match (EM) for extractive answers
  - F1 Score for extractive answers
  - ROUGE/BLEU for abstractive answers
  - Answer type accuracy (unanswerable detection)
  - Evidence recall (retrieval quality)
  - Retrieval precision@K

why_qasper:
  - Tests long-form document RAG (full documents vs paragraphs)
  - Real PDF text (headers, footers, formatting issues)
  - Domain-specific technical content
  - Multi-hop reasoning requirements
  - Diverse answer types
  - Evidence grounding enables retrieval evaluation
